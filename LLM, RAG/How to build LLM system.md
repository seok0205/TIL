# how to build LLM system

## LLM의 사용 준비

- LLM을 실무에서 사용하기 위해선 보안 문제, API 개념, 오픈 소스 LLM 구축에 대한 이해가 필수적.

### 보안 문제

- 대화형 AI인 LLM은 사용자의 민감한 정보를 처리할 가능성이 있으므로 데이터 유출, 프라이버시 침해가 발생하지 않도록 주의해야함.

#### LLM 활용 시 데이터 보안 문제

1. 개인 정보 보호 : 개인 정보 저장 혹은 제 3자 공유시 문제 발생.
2. 데이터 저장 및 전송 : 데이터 저장 장소, 방식을 확인해야 함. 암호화된 전송 방식(ex. HTTPS) 활용해 데이터 보호.
3. 모델 학습 데이터 : LLM은 학습에 사용된 데이터에 의존해 답변 생성. 만약 학습 데이터에 민감한 정보가 포함 시, 해당 정복 모델 출력으로 등장할 수 있음.

#### 보안 강화 방법

1. __민감 정보 필터링__ :  
    입력된 데이터 처리 전에 민감한 정보를 자동으로 거르는 필터링 시스템 구축.  

2. __암호화__ :  
    데이터는 저장 및 전송 중에 암호화되어야 함. 특히 SSL/TLS 같은 안전한 전송 프로토콜을 사용해야 함.  

3. __데이터 저장 최소화__ :  
    필요 이상으로 데이터 저장 X, 필요한 경우에도 데이터 보존 주기를 설정해 자동 삭제하도록 함.  

4. __접근 통제__ :  
    LLM을 사용할 수 있는 사람의 권한을 제한, 모델이 민감한 데이터에 접근하지 않도록 제한.  

### API(Application Programming Interface)

- 서로 다른 SW 시스템 간에 데이터와 기능을 주고받을 수 있도록 해주는 인터페이스. 즉, 두 프로그램이 서로 소통할 수 있는 다리.

#### 기본 개념

- __클라이언트-서버 모델__ :  
    클라이언트(요청하는 쪽)가 서버(응답하는 쪽)에게 데이터를 요청하면, 서버는 해당 데이터를 처리해 클라이언트에게 반환한다.  

- __HTTP/HTTPS protocol__ :  
    대부분의 API는 HTTP나 HTTPS를 통해 요청과 응답이 이루어짐.  

- __RESTful API__ :  
    가장 흔히 사용되는 API 설계 방식. 각 엔드포인트(URI)와 HTTP 메소드(GET, POST, PUT, DELETE 등)를 사용해 데이터 주고받음.  

#### API 사용의 주요 장점

- __유연성__ :  
    필요할 때마다 요청을 보내어 결과를 받을 수 있어, 실시간으로 다양한 애플리케이션에 적용 가능.  
- __확장성__ :  
    다양한 서비스, 플랫폼에 쉽게 통합할 수 있어, 여러 사용자가 동시에 사용할 수 있는 확장성을 가짐.  
- __업데이트__ :  
    LLM API 제공사가 모델을 업데이트하면 별다른 수정 없이 최신 기능을 바로 사용할 수 있음.  
- __비용 효율성__ :  
    API 호출에 따라 비용이 청구됨. 대규모 서버 유지할 필요 없이 필요한 만큼만 사용 가능.  

- ChatGPT 같은 LLM을 API로 사용하는 건 매우 효율적임. 이 API를 통해 다양한 애플리케이션에 LLM 기능을 쉽게 통합할 수 있음.

## Vector DB, LangChain, RAG

### Vector DB

- 문서나 데이터의 임베딩(Embedding) 벡터를 저장, 이 벡터를 바탕으로 유사한 데이터를 빠르게 찾을 수 있는 DB.
- LLM과 결합 시 유사 문서 검색이나 추천 시스템 등에 활용 가능.

#### Faiss

- Facebook AI Research에서 개발한 벡터 검색 엔진, Vector DB 구현 시 자주 사용. 대규모 벡터를 효율적으로 검색하고, 유사도를 계산하는 데 탁월한 성능을 발휘함. 특히 빠른 속도와 확장성이 필요한 애플리케이션에서 많이 쓰임.

### LangChain

- LLM과 Vector DB, 즉 언어 모델을 중심으로 다양한 데이터 소스와 툴들을 연결해주는 Python 기반 Framework. 데이터 흐름을 관리하고 API 호출을 더 간편하게 만들어 줌.
  
- 하나의 언어 모델 응답만 받는 대신, 여러 단계로 구성된 체인 구조를 통해 다양한 연산, 데이터 처리, 멀티스텝 분석이 가능.
  
- 예로 특정 질문에 대해 외부 DB에서 정보를 검색하고, 이를 종합해 응답을 생성하는 과정 등을 자동화할 수 있음.

#### LangChain 주요 개념

1. __프롬프트 템플릿(Prompt Templates)__
    - 프롬프트를 동적으로 생성하는 데 사용. 특정 입력 값에 따라 템플릿이 채워져 모델에 전달되어 반복적인 작업을 단순화시킴.

2. __Chains__
    - 여러 단계를 거치는 워크플로우를 하나로 묶는 기능. 예로 사용자 질문을 받은 후 검색->분석->응답 생성의 3단계 체인 생성.

3. __Agents__
    - 동적으로 필요한 작업을 결정하고 수행하는 컴포넌트. 질문에 따른 답변을 위해 API 호출 혹은 텍스트 생성이 필요한지 판단 후 실행.

#### LangChain의 장점

1. __유연한 구성__
    - 언어 모델과 다양한 컴포넌트를 쉽게 연결할 수 있음. 모델의 응답을 다른 컴포넌트로 보내거나, 여러 단계에 걸친 데이터 처리 가능.
  
2. __모듈화된 컴포넌트__
    - 프롬프트 템플릿, 출력 파서, Vector DB, Agents 등을 통해 각 컴포넌트를 필요에 따라 조합 가능. (재사용성, 확장성)
  
3. __체인과 에이전트__
    - 단순한 질문-응답을 넘어 여러 작업을 순차적으로 실행하는 체인과 상황에 따라 행동을 결정하는 에이전트를 통해 복잡한 작업을 자동화 가능.
  
4. __강력한 통합 기능__
    - OpenAI, HuggingFace, FAISS, ElasticSearch 등 다양한 언어 모델, Vector DB와의 통합이 가능해 데이터 소스 확장, 빠른 검색이 가능.

#### LangChain 사용 사례

1. RAG : 질문 답할 때, 관련 문서 검색, 해당 내용 바탕으로 최신 정보에 기반한 응답 생성 가능.
2. FAQ System : 다양한 질문에 대한 답을 Vector DB에 저장. 유사성 검색 통해 빠른 답변 제공.
3. 다단계 챗봇 워크플로우 : 복잡한 질문에 대해 여러 단계를 거쳐 답변을 구성하는 챗봇 설계.
4. 지능형 에이전트 : 주식 가격 확인, 뉴스 데이터 검색 후 최신 정보 제공 챗봇 에이전트 구현 가능.

### RAG(Retrieval-Augmented Generation)

- LLM과 검색 시스템을 결합한 개념. LLM의 한계를 외부 정보 검색을 통해 보완. 최신 정보 포함한 답변을 제공하는 데 매우 유리.

#### RAG 동작 원리

1. Retrieval(검색) 단계 :  
    사용자가 질문 시, Vector DB에서 질문과 유사한 문서나 데이터를 검색. 임베딩 모델 활용해 질문을 벡터로 변환, 벡터 간 유사도 계산으로 관련 데이터 탐색.  

2. Generation(생성) 단계 :  
    검색된 문서 LLM에 전달, 이를 바탕으로 자연스러운 답변 생성. 검색된 문서를 참조해 최신 정보를 포함한 정확한 답변을 제공.  

#### RAG 장점

- __최신 정보 제공__ : LLM의 학습 데이터 외 최신 문서 검색으로 정보 정확도 상승.
- __유연성__ : LLM이 모르는 정보도 외부 검색을 통해 답변. 지식의 확장성 뛰어남.
- __지식의 한계 극복__ : 학습 데이터 의존 X, 외부 DB에서 실시간 정보를 제공받아 더욱 풍부한 답변 가능.

### LLM + Vector DB + LangChain 구축 플로우

1. __텍스트 임베딩 생성__ : LLM으로 텍스트를 벡터(임베딩)로 변환.
2. __벡터 DB 저장__ : 변환된 벡터(임베딩)를 Vector DB에 저장.
3. __질문 처리__ : 사용자의 질문을 벡터로 변환, Vector DB에서 유사한 벡터를 찾음.
4. __답변 생성__ : 찾은 유사한 데이터와 함께 LLM 통해 최종 답변 생성.
5. __API로 제공__ : LangChain 통해 API 형태로 제공, 실제 서비스에서 사용 가능.

- [LangChain, FAISS 활용 실습](./실습/Langchain,%20FAISS.ipynb)

### Vector DB + RAG

- Vector DB는 유사한 문서 검색, RAG는 검색된 문서를 바탕으로 정확한 답변 생성하는 과정.

    동작 흐름  
        1. 사용자 질문  
        2. 질문 임베딩 생성  
        3. 벡터 DB에서 유사한 문서 검색  
        4. 문서 기반 LLM 답변 생성  
  
[한국어 데이터 임베딩 실습 코드](./실습/Korean%20Sentence%20Embedding.py)  

## 텍스트 처리 및 임베딩

### 텍스트 처리

#### 텍스트 처리가 중요한 이유

- 데이터의 품질을 높이고 모델의 성능을 향상시키기 위한 필수 작업. 자연어는 매우 복잡하고 다양하기 때문에, LLM이 텍스트를 정확하게 이해하고 처리하기 위해서는 데이터가 구조화되고 정제될 필요가 있음. 잘못된 텍스트 처리는 모델이 혼동하거나 잘못된 추론을 야기함.

#### 텍스트 처리의 목표

- __노이즈 제거__ : 텍스트 내 불필요한 정보나 오류를 제거해 정확한 분석을 도움.
- __일관성 확보__ : 문장 구조나 형태를 일관되게 유지해 모델이 더 쉽게 패턴을 학습할 수 있게 도움.
- __효율적 처리__ : 불필요 단어 제거, 중요한 정보만 남김. 모델의 더 빠른 계산을 도움.

#### 텍스트 처리 주요 기법

1. __토큰화(Tokenization)__
    - 텍스트를 단어 or 서브워드 단위로 나누는 작업. 텍스트를 숫자로 변환하기 전의 가장 중요한 단계.
  
    - __단어 단위 토큰화__ : 텍스트를 단어 단위로 나누는 기본 방법.
        - ex. '내 이름은 정석' -> ['내', '이름은', '정석']  
  
    - __서브워드 토큰화__ : 단어를 더 작은 단위로 분리해 새로운 단어를 처리할 수 있도록 하는 것. BPE, WordPiece 등이 있음.
        - ex. '읽었다' -> ['읽', '었다']  
  
    - 나눠진 토큰은 모델이 이해할 수 있는 형태로 변환됨.
  
2. __정규화(Normalization)__
    - 텍스트를 표준화된 형식으로 변환하는 작업. 텍스트에 포함된 대소문자, 특수문자 등을 일관되게 변환. 모델이 불필요한 변동에 혼란 겪지 않도록 함.
  
    - __소문자 변환__ : 대문자, 소문자 통일해 같은 단어로 인식하게 함.
  
    - __불필요한 기호 제거__ : 분석에 필요 없는 특수문자, 기호 제거.
  
    - 정규화로 모델이 텍스트의 의미에 집중 가능.
  
3. __불용어 제거(Stopword Removal)__
    - 불용어는 자주 등장하지만 정보가 없는 단어를 뜻함. 예로 '그리고', '이', '는' 같은 단어는 문맥에 큰 영향을 미치지 않아 불용어로 처리. 이를 제거하면 모델이 중요한 단어에만 집중 가능.
        - ex. 나는 프랑스에 갔다. -> ['프랑스', '갔다']
  
4. __형태소 분석(Morphological Analysis)__
    - 한국어와 같은 교착어에서는 형태소 분석이 필수적. 형태소는 단어의 최소 의미 단위를 말함. 특히 조사, 어미와 같은 부분을 정확히 분리하는 데 유용.
        - ex. '책을 읽었다' -> [책(noun), 을(postposition), 읽었다(verb)]
  
5. __어간 추출과 표제어 추출(Stemming and Lemmatization)__
    - 텍스트에서 동사나 형용사의 변형을 기본 형태로 돌리는 작업. 동일한 단어를 일관되게 처리 가능.
  
    - __어간 추출__ : 어미 제거, 기본 어간만 남김  
        ex. studying, studied, study -> study  
    - __표제어 추출__ : 단어를 사전적 기본형으로 변환  
        ex. am, is, are -> be  
  
6. __문장 분리 및 길이 조정__
    - 텍스트가 너무 길거나 복잡할 경우, 적절히 나누거나 길이를 조정해야 함. 긴 문장 처리 시, 모델의 메모리 제한이나 성능 저하를 방지할 수 있음.

### 임베딩(Embedding)

- 텍스트나 이미지 등의 비정형 데이터를 고차원 공간에서 벡터(숫자 배열)로 벡터화(Embedding)해서 저장. 이 벡터는 데이터의 의미나 특징을 수치로 표현하나 것. 이를 바탕으로 유사도 계산해 관련성이 높은 항목을 찾음.

- 임베딩 벡터는 단어의 의미나 문장의 문맥을 반영하여, 유사한 의미를 가진 텍스트는 유사한 벡터 값을 가짐.

- 임베딩을 활용하면 텍스트 검색, 문서 분류, 대화형 AI 등 다양한 응용 분야에서의 의미 기반 검색과 유사성 분석을 수행할 수 있음.

#### 임베딩 주요 기법

1. __Bag of Words(BoW)__
    - 단어의 빈도만을 기반으로 텍스트를 벡터화하는 단순한 방법. 단어 순서나 문맥을 고려하지 않아 의미 파악에 한계가 있음. 간단한 문서 분류나 텍스트 분석에 유용.
  
2. __TF-IDF(Term Frequency-Inverse Document Frequency)__
    - 단어 빈도 외에도 단어의 중요도를 반영. 특정 단어가 문서 내에서 자주 등장하지만 전체 문서에서 드물게 등장하면, 그 단어는 해당 문서에서 중요한 단어로 간주.
    - TF : 단어의 빈도.
    - IDF : 단어의 전체 문서에서의 등장 빈도 반비례값.
    - 이를 통해 문서 내에서 의미 있는 단어 강조 가능.
  
3. __Word2Vec, GloVe__
    - 단어 간의 의미적 유사성을 반영하는 기법. 단어를 고차원 벡터로 변환해서 단어 간의 관계를 학습함.
    - Word2Vec : 주위 단어들에 기반해 단어의 의미를 학습.
    - GloVe : 전체 문맥을 기반으로 단어 간의 공통 패턴을 학습.
    - 단어의 의미를 벡터로 비교해 문맥 유사성을 파악할 수 있음.

4. __Transformer 기반 임베딩(BERT, GPT)__
    - 모델들은 문장의 문맥을 고려해 더 깊이 있는 의미를 반영한 임베딩을 생성. 특히, 문장 단위로 텍스트를 벡터화할 수 있어서 문장 간 유사도를 정확히 파악함.
    - BERT : 양방향으로 문맥을 고려한 임베딩 생성.
    - GPT : 자동 완성 및 생성에 강점을 둔 임베딩 생성.
