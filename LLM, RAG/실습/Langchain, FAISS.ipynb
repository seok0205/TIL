{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Langchain, FAISS\n",
    "\n",
    "- LangChain 사용 위한 환경 설정과 FAISS로 Vector DB를 구성하는 실습\n",
    "\n",
    "## 설치 및 기본 설정\n",
    "\n",
    "'pip install langchain langchain-openai faiss-cpu'  \n",
    "  \n",
    "- LangChain, OpenAI, FAISS 패키지 설치.  \n",
    "  \n",
    "- 설치 후, OpenAI API 키 설정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path='key.env')\n",
    "api_key=os.getenv(\"GROUP_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain 기본 개념\n",
    "\n",
    "1. __언어 모델 초기화__\n",
    "\n",
    "- GPT-4 모델을 LangChain 통해 사용. ChatOpenAI를 이용해 초기화, invoke 메서드로 메시지 전달해 응답 받아옴."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자의 요청을 듣고 있습니다. 무엇을 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# 모델 초기화\n",
    "model = ChatOpenAI(model=\"gpt-4\", api_key=api_key)\n",
    "\n",
    "# 모델에 메시지 전달\n",
    "response = model.invoke([HumanMessage(content=\"안녕하세요, 무엇을 도와드릴까요?\")])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. __프롬프트 템플릿 사용하기__\n",
    "\n",
    "- 다양한 입력을 받아 메시지 생성에 도움을 줌. 영어 문장을 다른 언어로 번역하는 프롬프트 정의."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='Translate the following sentence from English to French:', additional_kwargs={}, response_metadata={}), HumanMessage(content='How are you?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 시스템 메시지 설정\n",
    "system_template = \"Translate the following sentence from English to {language}:\"\n",
    "\n",
    "# 사용자 텍스트 입력\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_template),\n",
    "    (\"user\", \"{text}\")\n",
    "])\n",
    "\n",
    "# 프롬프트 생성\n",
    "result = prompt_template.invoke({\"language\": \"French\", \"text\": \"How are you?\"})\n",
    "print(result.to_messages())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain Expression Language(LCEL)로 체인 연결\n",
    "\n",
    "- 여러 컴포넌트를 체인으로 연결해서 데이터 흐름을 통제하는 LCEL 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Dónde está la biblioteca?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 응답을 파싱하는 파서 초기화\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 템플릿, 모델, 파서를 체인으로 연결\n",
    "chain = prompt_template | model | parser\n",
    "\n",
    "# 체인 실행\n",
    "response = chain.invoke({\"language\": \"Spanish\", \"text\": \"Where is the library?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAISS 활용 Vector DB 구성 및 쿼리\n",
    "\n",
    "- FAISS는 벡터 유사성 검색 위한 라이브러리. OpenAIEmbeddings로 텍스트를 벡터로 변환해서 FAISS index에 저장.\n",
    "\n",
    "1. OpenAI Embedding model로 Vector Embedding 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# OpenAI 임베딩 모델 초기화\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. FAISS index 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "# FAISS 인덱스 생성\n",
    "index = faiss.IndexFlatL2(len(embeddings.embed_query(\"hello world\")))\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Vector DB에 문서 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a8399d99-da34-4144-b9d5-178db922c535',\n",
       " '3464d19d-58ab-4894-8e6c-60a99920e8eb',\n",
       " '691cbde2-f432-4586-b095-3c118c028c55',\n",
       " 'ae042198-fbfc-4c1b-a6a0-262cf78f1ebd']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from uuid import uuid4\n",
    "\n",
    "# 문서 생성\n",
    "documents = [\n",
    "    Document(page_content=\"LangChain을 사용해 프로젝트를 구축하고 있습니다!\", metadata={\"source\": \"tweet\"}),\n",
    "    Document(page_content=\"내일 날씨는 맑고 따뜻할 예정입니다.\", metadata={\"source\": \"news\"}),\n",
    "    Document(page_content=\"오늘 아침에는 팬케이크와 계란을 먹었어요.\", metadata={\"source\": \"personal\"}),\n",
    "    Document(page_content=\"주식 시장이 경기 침체 우려로 하락 중입니다.\", metadata={\"source\": \"news\"}),\n",
    "]\n",
    "\n",
    "# 고유 ID 생성 및 문서 추가\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Vector DB Query\n",
    "\n",
    "- 유사성 검색을 통해 특정 쿼리와 유사한 문서를 검색."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 내일 날씨는 맑고 따뜻할 예정입니다. [{'source': 'news'}]\n",
      "* 주식 시장이 경기 침체 우려로 하락 중입니다. [{'source': 'news'}]\n",
      "* [SIM=0.159] LangChain을 사용해 프로젝트를 구축하고 있습니다! [{'source': 'tweet'}]\n"
     ]
    }
   ],
   "source": [
    "# 기본 유사성 검색\n",
    "results = vector_store.similarity_search(\"내일 날씨는 어떨까요?\", k=2, filter={\"source\": \"news\"})\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")\n",
    "\n",
    "# 점수와 함께 유사성 검색\n",
    "results_with_scores = vector_store.similarity_search_with_score(\"LangChain에 대해 이야기해주세요.\", k=2, filter={\"source\": \"tweet\"})\n",
    "for res, score in results_with_scores:\n",
    "    print(f\"* [SIM={score:.3f}] {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Chain에 FAISS 통합\n",
    "\n",
    "- RAG 체인을 구성하여 검색된 문서를 바탕으로 질문에 응답할 수 있도록 구성.\n",
    "\n",
    "1. FAISS를 Retriever로 변환해 RAG 체인에서 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. RAG Chain 생성\n",
    "\n",
    "- LangChain의 모델과 프롬프트를 연결하여 RAG 체인을 구성함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug Output: 내일 날씨는?\n",
      "Debug Output: {'context': [Document(metadata={'source': 'news'}, page_content='내일 날씨는 맑고 따뜻할 예정입니다.')], 'question': '내일 날씨는?'}\n",
      "Final Response:\n",
      "맑고 따뜻할 예정입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "contextual_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the question using only the following context.\"),\n",
    "    (\"user\", \"Context: {context}\\\\n\\\\nQuestion: {question}\")\n",
    "])\n",
    "\n",
    "\n",
    "class DebugPassThrough(RunnablePassthrough):\n",
    "    def invoke(self, *args, **kwargs):\n",
    "        output = super().invoke(*args, **kwargs)\n",
    "        print(\"Debug Output:\", output)\n",
    "        return output\n",
    "# 문서 리스트를 텍스트로 변환하는 단계 추가\n",
    "class ContextToText(RunnablePassthrough):\n",
    "    def invoke(self, inputs, config=None, **kwargs):  # config 인수 추가\n",
    "        # context의 각 문서를 문자열로 결합\n",
    "        context_text = \"\\n\".join([doc.page_content for doc in inputs[\"context\"]])\n",
    "        return {\"context\": context_text, \"question\": inputs[\"question\"]}\n",
    "\n",
    "# RAG 체인에서 각 단계마다 DebugPassThrough 추가\n",
    "rag_chain_debug = {\n",
    "    \"context\": retriever,                    # 컨텍스트를 가져오는 retriever\n",
    "    \"question\": DebugPassThrough()        # 사용자 질문이 그대로 전달되는지 확인하는 passthrough\n",
    "}  | DebugPassThrough() | ContextToText()|   contextual_prompt | model\n",
    "\n",
    "# 질문 실행 및 각 단계 출력 확인\n",
    "response = rag_chain_debug.invoke(\"내일 날씨는?\")\n",
    "print(\"Final Response:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAISS index의 저장 및 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The de-serialization relies loading a pickle file. Pickle files can be modified to deliver a malicious payload that results in execution of arbitrary code on your machine.You will need to set `allow_dangerous_deserialization` to `True` to enable deserialization. If you do this, make sure that you trust the source of the data. For example, if you are loading a file that you created, and know that no one else has modified the file, then this is safe to do. Do not set this to `True` if you are loading a file from an untrusted source (e.g., some random site on the internet.).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m vector_store\u001b[38;5;241m.\u001b[39msave_local(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfaiss_index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 저장된 인덱스 로드\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m new_vector_store \u001b[38;5;241m=\u001b[39m \u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_local\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfaiss_index\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\By the book\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:1188\u001b[0m, in \u001b[0;36mFAISS.load_local\u001b[1;34m(cls, folder_path, embeddings, index_name, allow_dangerous_deserialization, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load FAISS index, docstore, and index_to_docstore_id from disk.\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \n\u001b[0;32m   1176\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;124;03m        arbitrary code on your machine.\u001b[39;00m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_dangerous_deserialization:\n\u001b[1;32m-> 1188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe de-serialization relies loading a pickle file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1190\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPickle files can be modified to deliver a malicious payload that \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults in execution of arbitrary code on your machine.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1192\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou will need to set `allow_dangerous_deserialization` to `True` to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menable deserialization. If you do this, make sure that you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust the source of the data. For example, if you are loading a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1195\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile that you created, and know that no one else has modified the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1196\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile, then this is safe to do. Do not set this to `True` if you are \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading a file from an untrusted source (e.g., some random site on \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1198\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe internet.).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1199\u001b[0m     )\n\u001b[0;32m   1200\u001b[0m path \u001b[38;5;241m=\u001b[39m Path(folder_path)\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;66;03m# load index separately since it is not picklable\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: The de-serialization relies loading a pickle file. Pickle files can be modified to deliver a malicious payload that results in execution of arbitrary code on your machine.You will need to set `allow_dangerous_deserialization` to `True` to enable deserialization. If you do this, make sure that you trust the source of the data. For example, if you are loading a file that you created, and know that no one else has modified the file, then this is safe to do. Do not set this to `True` if you are loading a file from an untrusted source (e.g., some random site on the internet.)."
     ]
    }
   ],
   "source": [
    "# 인덱스 저장\n",
    "vector_store.save_local(\"faiss_index\")\n",
    "\n",
    "# 저장된 인덱스 로드\n",
    "new_vector_store = FAISS.load_local(\"faiss_index\", embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAISS DB 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "db1 = FAISS.from_texts([\"문서 1 내용\"], embeddings)\n",
    "db2 = FAISS.from_texts([\"문서 2 내용\"], embeddings)\n",
    "\n",
    "# 병합\n",
    "db1.merge_from(db2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Seok",
   "language": "python",
   "name": "seok"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
