# LLM

- LLM(Large Language Model)(대형 언어 모델) :  
    대규모 텍스트 데이터를 학습하여 자연어를 이해하고 생성할 수 있는 수십억 개의 파라미터를 기반으로 한 AI 모델. 기본적으로 자연어 처리(NLP)의 다양한 작업, 예로 번역, 질문 응답, 텍스트 생성 등을 할 수 있다.

## 동작 원리

1. 학습(Training)  
    LLM은 대규모 텍스트 데이터셋을 이용해 학습.  
    __패턴 인식__ : 수많은 텍스트에서 단어와 문장의 패턴을 찾아내어, 새 문장이나 답변을 생성할 때 패턴을 적용.

2. 추론(Inference)  
    학습된 LLM은 질문이나 입력을 받으면, 그에 맞는 추론을 통해 답변을 생성. 이때, 이전의 맥락을 기억하고 활용하면서 답을 만듦.

3. 미세 조정(Fine-tuning)  
    LLM은 특정 도메인이나 용도에 맞춰 fine-tuning을 할 수 있다. 예로 의료나 법률 같은 특수한 분야에 맞는 데이터를 추가로 학습시키면 해당 분야에 대한 답변의 정확성이 높아진다.

## 랜덤성과 조건성

1. 랜덤성(Randomness)

    - 기본적으로 확률에 기반하여 문장을 생성. 따라서 같은 질문에도 같은 답변이 나오지 않을 수도 있다. 새로운 문장을 만들어내는 능력을 키우는 핵심 요소.
    - LLM이 결과를 생성할 때, 토큰의 확률 분포를 계사ㅏ나해 그 중 높은 확률을 가진 토큰을 선택해 문장을 만듦. 이때 'temperature'라는 매개변수가 랜덤성에 영향을 미침. 이 매개변수가 낮으면 일관성이 있고 예측이 가능한 답변을 생성하고, 높으면 창의적이고 예측이 어려운 결과가 나올 수 있다. 각각 랜덤성이 더 적고, 많다고 말할 수 있다.

2. 조건성(Conditioning)

    - LLM은 조건부 확률을 기반으로 결과를 도출. 즉, 모델은 이전 입력 내용에 따라 문장을 조건부로 생성하게 되는데, 이를 context라고 한다.
    - 위 과정에서 두 가지의 중요 요소가 있는데, 첫 번째는 입력된 문자아이나 질문이 무엇인지에 따라 결과가 달라지는 프롬프트, 두 번째로는 대화를 나누는 동안 이전 문장이나 대화 흐름을 기억하고 그에 맞춘 답을 생성하는 맥락 기억이 있다.

## LLM의 원리 요약

- 원리를 이해하면 정확한 프롬프트 작성이 가능해져서 원하는 답을 쉽게 얻을 수 있고, LLM의 한계를 안다면 적절한 상황에서의 도구 선택을 이끌어낼 수 있다. 또한 RAG나 LangChain 같은 성능 개선을 위한 기술 요소들도 효과적으로 도입할 수 있다.

1. 대규모 데이터 학습 : 언어 패턴 학습

2. 문맥 기반 추론 : 텍스트 맥락 파악으로 답 도출

3. 랜덤성 및 조건성 : 확률 기반 답변 생성, 조건에 따라 결과 상이

4. Fine-tuning : 특정 용도나 도메인에 맞춰 학습 가능

## 추가 개념

1. RAG(Retrieval-Augmented Generation) :  
    LLM이 스스로 모든 답을 생성하는 대신에 데이터베이스에서 정보를 검색한 것을 기반으로 답변을 생성하는 기법이고, LLM의 한계를 극복할 수 있는 방법 중 하나이다.

2. Vector DB :  
    텍스트를 벡터 형태로 변환하여 유사한 의미를 가진 텍스트를 효율적으로 검색할 수 있게 도와주는 기술. LLM과 결합 시 강력한 검색, 응답 기능을 구현 가능하다.
