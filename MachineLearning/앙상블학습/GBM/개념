GBM - Gradient Boosting Machine

여러 개의 약한 학습기를 순차적으로 학습시키고, 그 예측 결과를 결합해 강한 학습기 만드는 기법.
이전 모델이 잘못 예측한 데이터에 가중치를 부여하여 다음 모델이 더 잘 학습하도록 함.
각 트리가 독립적으로 학습, 과적합 방지, 예측 성능 향상.

구조 :
여러 개의 결정 트리(Decision Tree)로 구성
각 결정 트리는 이전 트리의 예측 오류를 보완하는 방식으로 학습.
GBM은 각 트리의 예측 결과를 가중합하여 최종 예측 수행.

원리 :
1. 첫 번째 결정 트리를 학습시켜 초기 모델을 만듦.
2. 초기 모델의 예측 결과와 실제 값 간의 잔여 오차를 계산.
3. 잔여 오차를 예측하는 새로운 결정 트리를 학습시킴.
4. 새로운 결정 트리를 기존 모델에 추가하여 모델을 업데이트한다.
5. 잔여 오차가 충분히 작아질 때까지 2~4단계를 반복.

GBM의 단계적 학습 :
단계적으로 학습을 진행하여, 이전 모델의 오류를 보완하는 방식으로 예측 성능을 향상시킴.
각 단계에서 학습된 모델은 이전 모델의 잔여 오차를 줄이는 데에 집중.