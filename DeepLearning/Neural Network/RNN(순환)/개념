RNN - Recurrent Neural Network(순환 신경망)

시계열 데이터나 순차적인 데이터를 처리하기 위해 설계된 신경망.
이전 시간 단계의 정보를 현재 시간 단계로 전달해, 시퀀스 데이터의 패턴을 학습할 수 있다.

동작 원리 :
    순환 구조 -
        입력 데이터와 이전 시간 단계의 은닉 상태를 입력으로 받아, 현재 시간 단계의 은닉 상태 출력.
        은닉 상태는 시퀀스의 정보를 저장하고, 다음 시간 단계로 전달.
    동작 원리 -
        시퀀스의 각 시간 단계에서 동일한 가중치 공유, 시퀀스의 패턴 학습.
        순전파(Forward Propagation), 역전파(Backpropagation Through Time, BPTT)를 통해 가중치 학습.

LSTM, GRU :
    장기 의존성 문제(long-term dependency problem) 해결하기 위해 개발.

    LSTM(Long Short-Term Momory) :
        셀 상태와 게이트 구조를 도입, 장기 의존성을 효과적으로 학습가능.
        입력 게이트, 출력 게이트, 망각(forget) 게이트를 사용하여 정보 조절.

    GRU(Gated Recurrent Unit) :
        LSTM의 변형. 셀 상태 대신 은닉 상태만 사용해 구조 단순화.
        업데이트 게이트와 리셋 게이트 사용해 정보 조절.

    차이점 :
        전자는 셀 상태와 은닉 상태를 모두 사용. 더 복잡한 게이트 구조.
        후자는 은틱 상태만 사용, 더 간단한 게이트 구조.(계산 비용 적고 학습 빠름.)

시계열 데이터 처리 방법 :
    ex. 주식 가격 예측, 날씨 예측, 텍스트 생성
    1. 데이터 전처리 :
        시계열 데이터를 전처리, 정규화한다. 입력, 출력 시퀀스 정의.
    2. 모델 구축 :
        RNN, LSTM, GRU 등 모델 정의.
    3. 모델 학습 :
        손실 함수와 최적화 알고리즘을 정의.
        순전파 역전파를 통해 모델을 학습.
    4. 모델 평가 :
        테스트 데이터를 사용하여 모델의 성능을 평가.