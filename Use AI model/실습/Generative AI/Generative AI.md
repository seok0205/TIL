# Generative AI (생성형 인공지능)

- 주어진 입력에 따라 새로운 콘텐츠를 생성하는 인공지능 기술. 예로, 텍스트 생성 모델은 몇 개의 단어를 입력받아 그에 맞는 문장을 생성하고, 이미지 생성 모델은 입력된 스케치를 바탕으로 사실적 이미지를 만듦.

- ex. 텍스트 생성 : GPT-3, ChatGPT  
    이미지 생성 : DALL-E, Stable Diffusion  
    음악 생성 : Magenta, Jukedeck, Jukebox(OpenAI)  

## Geverative AI를 직접 만드는 것의 어려움

1. 대규모 데이터와 컴퓨팅 자원 필요

    - Generative AI는 일반적으로 deep learning 기법을 상요하여 수십억 개의 파라미터를 가진 모델을 학습시킨다. 학습을 위해서는 방대한 양의 데이터와 강력한 컴퓨팅 자원이 필요하다.

    - __데이터 수집의 어려움__ : 수백만 개의 고품질 데이터가 필요.
    - __컴퓨팅 자원의 한계__ : GPU 혹은 TPU 같은 고성능 하드웨어에서 오랜 시간 학습을 해야 한다. 이러한 자원은 확보가 쉽지 않고, 클라우드 서비스를 사용해도 높은 비용이 발생할 수 있다.

2. 모델 구조의 복잡성

    - 매우 복잡한 모델 구조를 가지고 있다. 처음부터 구현하려면 높은 수준의 deep learning 지식과 경험이 필요하다.

    - __모델 아키텍처 설계__ : 여러 층의 신경망과 다양한 메커니즘(Attention 메커니즘, transformer 구조)을 포함하고 있어, 올바른 설계가 어려움.
    - __하이퍼파라미터 튜닝__ : 학습률, 배치 크기, 레이어 수 등 다양한 하이퍼파라미터의 조절로 최적의 성능을 낼 수 있음.

3. 훈련 과정의 불안정성

    - 학습 과정이 매우 불안정할 수 있다. 모델이 학습되지 않거나, 특정 패턴에 과적합(overfitting)되는 문제 등이 발생할 수 있다.

    - __모델 붕괴__ : 생성형 모델은 훈련 중 무작위하게 출력이 고정되거나 의미 없는 결과를 생성하는 모델 붕괴(model collapse) 현승을 겪을 수 있음.
    - __균형 잡힌 학습__ : 고품질의 출력을 생성하기 위해선 학습 데이터를 적절히 사용하고, 학습 과정에서 다양한 출력을 생성하도록 모델을 조절해야 한다.(섬세하게 관리)

## Fine-Tuning의 필요성

1. 사전 학습된 모델의 장점

    - 사전 학습 모델을 사용하면, 이미 방대한 데이터와 강력한 컴퓨팅 자원을 사용해 학습된 모델을 활용 가능. 예로, GPT-3같은 모델은 수조 개의 단어로 학습되었고, 이런 모델을 활용하면 생성형 AI 개발 과정에서 발생하는 어려움을 줄일 수 있다.

    - __시간과 비용 절감__ : 초기 학습 과정 생략, 필요한 작업에 맞춰 빠르게 튜닝 가능.
    - __높은 성능__ : 사전 학습 모델은 이미 일반적 언어 패턴을 학습한 상태, 적은 데이터와 자원으로도 높은 성능을 얻을 수 있다.

2. Fine Tuning의 필수성

    - fine-tuning으로 생성형 AI 모델을 특정 도메인이나 작업에 맞게 조정해야 한다. 사전 학습된 모델이 일반적 언어 구조나 패턴을 학습했다 해도, 특정 작업에 최적화하려면 추가적 학습이 필요하다.

    - __도메인 특화__ : 예로 의료 문서 생성을 만들고자 한다면, 일반적 텍스트 데이터로 학습된 모델을 의료 데이터로 fine-tuning하여 의료 용어와 패턴에 맞게 모델을 조정해야 한다.
    - __작업 맞춤__ : 특정 작업(ex. 특정 스타일의 글쓰기, 특정 형식의 이미지 생성)에 모델을 맞추기 위해  Fine-Tuning이 필수적.

## 직접 Generative AI를 만들고자 한다면

1. 사전 학습된 모델 활용 : 시작점으로 유용. Hugging Face, OpenAI 등에서 제공하는 사전 학습 모델을 활용해 Fine-Tuning을 진행하는 것이 효율적.

2. 클라우드 서비스 활용 : 강력한 컴퓨팅 자원이 필요하면, AWS, Google Cloud, Azure 같은 클라우드 서비스를 활용할 수 있다. 이들 서비스는 GPU/TPU 기반 인프라를 제공하여 대규모 모델을 효율적으로 학습시킬 수 있다.

3. 작은 프로젝트부터 시작하기
처음부터 대규모 생성 AI프로젝트를 시작하기보단, 작은 데이터셋과 간단한 모델로 실험을 시작하는 것이 좋다. 딥러닝 모델에 대한 이해를 높이고 점진적으로 복잡한 모델로 확장이 가능하다.
